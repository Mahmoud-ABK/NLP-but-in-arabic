{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8056f7b-27c5-4a06-9c75-7e0bb89fce14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:55:10.998845Z",
     "iopub.status.busy": "2025-12-22T06:55:10.998618Z",
     "iopub.status.idle": "2025-12-22T06:55:11.001759Z",
     "shell.execute_reply": "2025-12-22T06:55:11.001261Z",
     "shell.execute_reply.started": "2025-12-22T06:55:10.998827Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d24c84c-19bb-4888-9016-d54e97f1f107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:55:11.400904Z",
     "iopub.status.busy": "2025-12-22T06:55:11.400686Z",
     "iopub.status.idle": "2025-12-22T06:55:11.456989Z",
     "shell.execute_reply": "2025-12-22T06:55:11.456508Z",
     "shell.execute_reply.started": "2025-12-22T06:55:11.400889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Uniformed. Authors: 227, Train: 1161, Test: 291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('01-datatransformed.csv')\n",
    "authors = pd.read_csv(\"00-authors.csv\")\n",
    "\n",
    "# 1. Uniformize the Authors table IDs first\n",
    "authors['id'] = authors['id'].astype(str).str.strip()\n",
    "\n",
    "# 2. Improved parsing function to handle potential 'np.str_' literal text\n",
    "def clean_id_list(s):\n",
    "    if not isinstance(s, str) or not s or s == '[]': \n",
    "        return []\n",
    "    \n",
    "    # Remove brackets\n",
    "    content = s.strip(\"[]\")\n",
    "    # Split by comma\n",
    "    items = content.split(',')\n",
    "    \n",
    "    cleaned_items = []\n",
    "    for item in items:\n",
    "        # Remove whitespace and various types of quotes\n",
    "        clean = item.strip().strip(\"'\\\"\")\n",
    "        # Remove literal \"np.str_(\" if it was accidentally saved into the CSV text\n",
    "        clean = clean.replace(\"np.str_(\", \"\").replace(\")\", \"\").strip(\"'\\\"\")\n",
    "        if clean:\n",
    "            cleaned_items.append(str(clean)) # Force to standard Python string\n",
    "            \n",
    "    return cleaned_items\n",
    "\n",
    "# 3. Apply cleaning to the main dataframe\n",
    "df['author_ids'] = df['author_ids'].apply(clean_id_list)\n",
    "\n",
    "# 4. Handle NaNs\n",
    "df.fillna({'text_for_tfidf': ''}, inplace=True)\n",
    "\n",
    "# 5. Re-split the data to ensure train/test sets are also clean\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Data Uniformed. Authors: {len(authors)}, Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ded264bc-e1ca-41d8-bab4-d0d32ee319a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:55:14.572897Z",
     "iopub.status.busy": "2025-12-22T06:55:14.572664Z",
     "iopub.status.idle": "2025-12-22T06:55:14.643479Z",
     "shell.execute_reply": "2025-12-22T06:55:14.642884Z",
     "shell.execute_reply.started": "2025-12-22T06:55:14.572880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1161, 6)\n",
      "Testing set shape: (291, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Testing set shape: {test_df.shape}\")\n",
    "\n",
    "# --- 3. Save the Splits to CSV ---\n",
    "train_df.to_csv('02-train.csv', index=False, encoding='utf-8-sig')\n",
    "test_df.to_csv('02-test.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a23ef43d-75e3-46a8-9be4-a8de2a4425af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:55:16.277552Z",
     "iopub.status.busy": "2025-12-22T06:55:16.277288Z",
     "iopub.status.idle": "2025-12-22T06:55:16.407674Z",
     "shell.execute_reply": "2025-12-22T06:55:16.407220Z",
     "shell.execute_reply.started": "2025-12-22T06:55:16.277532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted. Vocabulary size: 5601\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Load the splits\n",
    "train_df = pd.read_csv('02-train.csv')\n",
    "test_df = pd.read_csv('02-test.csv')\n",
    "\n",
    "# 2. Re-parse author_ids (since CSV saves lists as strings)\n",
    "def parse_list(s):\n",
    "    if not isinstance(s, str) or not s: return []\n",
    "    return [item.strip().strip(\"'\\\"\") for item in s.strip(\"[]\").split(',')]\n",
    "\n",
    "train_df['author_ids'] = train_df['author_ids'].apply(parse_list)\n",
    "test_df['author_ids'] = test_df['author_ids'].apply(parse_list)\n",
    "\n",
    "# 3. Fit TF-IDF on Training Data\n",
    "# We use sublinear_tf to scale counts and min_df to ignore very rare typos\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=2, ngram_range=(1, 1)) \n",
    "tfidf_matrix = tfidf.fit_transform(train_df['text_for_tfidf'].fillna(''))\n",
    "\n",
    "print(f\"Model fitted. Vocabulary size: {len(tfidf.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad7f0198-2823-4807-899a-ea5ce608049b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:55:17.643495Z",
     "iopub.status.busy": "2025-12-22T06:55:17.643226Z",
     "iopub.status.idle": "2025-12-22T06:55:17.650682Z",
     "shell.execute_reply": "2025-12-22T06:55:17.650231Z",
     "shell.execute_reply.started": "2025-12-22T06:55:17.643472Z"
    }
   },
   "outputs": [],
   "source": [
    "def recommend_reviewer_logic_verbose(query_text, k_depth=20):\n",
    "    \"\"\"\n",
    "    Verbose implementation of Sequential Disambiguation logic.\n",
    "    Provides a step-by-step trace of the recommendation process.\n",
    "    \"\"\"\n",
    "    print(\"-\" * 60)\n",
    "    print(\"STARTING RECOMMENDATION PROCESS\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # 1. Vectorize input\n",
    "    query_vec = tfidf.transform([query_text])\n",
    "    \n",
    "    # 2. Calculate similarities\n",
    "    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    \n",
    "    # 3. Get Top K indices\n",
    "    top_indices = similarities.argsort()[::-1][:k_depth]\n",
    "    \n",
    "    # 4. STEP 1: Anchor Candidates\n",
    "    best_match_idx = top_indices[0]\n",
    "    best_score = similarities[best_match_idx]\n",
    "    best_article_id = train_df.iloc[best_match_idx]['article_id']\n",
    "    candidates = set(train_df.iloc[best_match_idx]['author_ids'])\n",
    "    \n",
    "    print(f\"[STEP 1] ANCHOR MATCH FOUND\")\n",
    "    print(f\"Nearest Article ID: {best_article_id}\")\n",
    "    print(f\"Similarity Score:   {best_score:.4f}\")\n",
    "    print(f\"Initial Candidates: {candidates}\")\n",
    "\n",
    "    # Safety check for zero similarity\n",
    "    if best_score == 0:\n",
    "        print(\"[ERROR] No similar articles found (Score is 0).\")\n",
    "        return None, None, \"No Matches\"\n",
    "\n",
    "    # If article 1 has only one author, return immediately\n",
    "    if len(candidates) == 1:\n",
    "        winner = list(candidates)[0]\n",
    "        print(f\"[RESULT] Unique author found in nearest article. Selecting: {winner}\")\n",
    "        return winner, best_article_id, \"Direct Match\"\n",
    "\n",
    "    # 5. STEP 2: Disambiguation Loop\n",
    "    print(f\"\\n[STEP 2] DISAMBIGUATION (Tie between {len(candidates)} authors)\")\n",
    "    print(f\"Scanning up to {k_depth} nearest matches for a tie-breaker...\")\n",
    "    \n",
    "    for i in range(1, len(top_indices)):\n",
    "        next_match_idx = top_indices[i]\n",
    "        next_score = similarities[next_match_idx]\n",
    "        next_id = train_df.iloc[next_match_idx]['article_id']\n",
    "        next_authors = set(train_df.iloc[next_match_idx]['author_ids'])\n",
    "        \n",
    "        # Calculate intersection\n",
    "        overlap = candidates.intersection(next_authors)\n",
    "        \n",
    "        print(f\"\\nRank {i+1} | Article {next_id} | Score: {next_score:.4f}\")\n",
    "        print(f\"Article authors: {next_authors}\")\n",
    "        \n",
    "        if len(overlap) == 0:\n",
    "            print(\"No overlap with current candidates. Continuing...\")\n",
    "            continue\n",
    "            \n",
    "        elif len(overlap) == 1:\n",
    "            winner = list(overlap)[0]\n",
    "            print(f\"[RESULT] Found unique tie-breaker at rank {i+1}\")\n",
    "            print(f\"Winner identified: {winner}\")\n",
    "            print(\"-\" * 60)\n",
    "            return winner, best_article_id, f\"Tie broken by rank {i+1}\"\n",
    "        \n",
    "        else: # len(overlap) > 1\n",
    "            print(f\"Multiple candidates match ({overlap}). Narrowing candidate pool.\")\n",
    "            candidates = overlap\n",
    "            \n",
    "    # 6. STEP 3: Fallback\n",
    "    print(f\"\\n[STEP 3] FALLBACK\")\n",
    "    print(f\"Checked all {k_depth} articles. Tie persists between: {candidates}\")\n",
    "    winner = random.choice(list(candidates))\n",
    "    print(f\"Action: Randomly selecting from remaining candidates: {winner}\")\n",
    "    print(\"-\" * 60)\n",
    "    return str(winner), best_article_id, \"Random Fallback (Tie)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7fd2a296-49d2-4601-b6dc-196cdb420ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:55:35.990107Z",
     "iopub.status.busy": "2025-12-22T06:55:35.989881Z",
     "iopub.status.idle": "2025-12-22T06:55:35.993558Z",
     "shell.execute_reply": "2025-12-22T06:55:35.993047Z",
     "shell.execute_reply.started": "2025-12-22T06:55:35.990090Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_author_name(auth_id):\n",
    "    if auth_id is None: \n",
    "        return \"N/A\"\n",
    "    \n",
    "    # Force search ID to string and strip any quotes\n",
    "    search_id = str(auth_id).strip().strip(\"'\\\"\")\n",
    "    \n",
    "    # Search in authors dataframe\n",
    "    match = authors[authors['id'] == search_id]\n",
    "    \n",
    "    if not match.empty:\n",
    "        return match.iloc[0]['name']\n",
    "    else:\n",
    "        # Debugging: if not found, let's see what the ID actually looks like\n",
    "        return f\"Unknown ({search_id})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3dbef01-a849-4985-abe8-a340707a3846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:57:15.007793Z",
     "iopub.status.busy": "2025-12-22T06:57:15.007557Z",
     "iopub.status.idle": "2025-12-22T06:57:15.018396Z",
     "shell.execute_reply": "2025-12-22T06:57:15.017885Z",
     "shell.execute_reply.started": "2025-12-22T06:57:15.007775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "STARTING RECOMMENDATION PROCESS\n",
      "------------------------------------------------------------\n",
      "[STEP 1] ANCHOR MATCH FOUND\n",
      "Nearest Article ID: 1035\n",
      "Similarity Score:   1.0000\n",
      "Initial Candidates: {'AUTH_00095', 'AUTH_00055', 'AUTH_00003', 'AUTH_00189'}\n",
      "\n",
      "[STEP 2] DISAMBIGUATION (Tie between 4 authors)\n",
      "Scanning up to 20 nearest matches for a tie-breaker...\n",
      "\n",
      "Rank 2 | Article 510 | Score: 1.0000\n",
      "Article authors: {'AUTH_00010'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 3 | Article 752 | Score: 1.0000\n",
      "Article authors: {'AUTH_00160', 'AUTH_00114'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 4 | Article 39 | Score: 0.1117\n",
      "Article authors: {'AUTH_00026'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 5 | Article 94 | Score: 0.1095\n",
      "Article authors: {'AUTH_00125', 'AUTH_00120', 'AUTH_00118', 'AUTH_00126', 'AUTH_00122', 'AUTH_00117', 'AUTH_00121', 'AUTH_00124', 'AUTH_00119', 'AUTH_00116', 'AUTH_00123'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 6 | Article 603 | Score: 0.1091\n",
      "Article authors: {'AUTH_00115', 'AUTH_00122'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 7 | Article 1442 | Score: 0.1091\n",
      "Article authors: {'AUTH_00174', 'AUTH_00032'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 8 | Article 858 | Score: 0.1091\n",
      "Article authors: {'AUTH_00144'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 9 | Article 1142 | Score: 0.1091\n",
      "Article authors: {'AUTH_00152'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 10 | Article 265 | Score: 0.1061\n",
      "Article authors: {'AUTH_00100'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 11 | Article 558 | Score: 0.1061\n",
      "Article authors: {'AUTH_00033', 'AUTH_00004', 'AUTH_00171'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 12 | Article 1093 | Score: 0.1061\n",
      "Article authors: {'AUTH_00166', 'AUTH_00199', 'AUTH_00057'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 13 | Article 1273 | Score: 0.1055\n",
      "Article authors: {'AUTH_00115', 'AUTH_00207'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 14 | Article 972 | Score: 0.1055\n",
      "Article authors: {'AUTH_00025', 'AUTH_00190'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 15 | Article 1565 | Score: 0.1055\n",
      "Article authors: {'AUTH_00147'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 16 | Article 443 | Score: 0.1055\n",
      "Article authors: {'AUTH_00200'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 17 | Article 587 | Score: 0.1034\n",
      "Article authors: {'AUTH_00146'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 18 | Article 1425 | Score: 0.1034\n",
      "Article authors: {'AUTH_00120'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 19 | Article 841 | Score: 0.1034\n",
      "Article authors: {'AUTH_00011', 'AUTH_00162'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "Rank 20 | Article 53 | Score: 0.1018\n",
      "Article authors: {'AUTH_00048'}\n",
      "No overlap with current candidates. Continuing...\n",
      "\n",
      "[STEP 3] FALLBACK\n",
      "Checked all 20 articles. Tie persists between: {'AUTH_00095', 'AUTH_00055', 'AUTH_00003', 'AUTH_00189'}\n",
      "Action: Randomly selecting from remaining candidates: AUTH_00003\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "FINAL INFERENCE SUMMARY\n",
      "------------------------------------------------------------\n",
      "Actual Authors:      ['AUTH_00131', 'AUTH_00100']\n",
      "Actual Names:        Mohammed Asaad Diab Ewaiwi, Nadha Mutlaq ALbogami\n",
      "------------------------------------------------------------\n",
      "Recommended ID:      AUTH_00003\n",
      "Recommended Name:    محمد عبود الحراحشة\n",
      "Selection Method:    Random Fallback (Tie)\n"
     ]
    }
   ],
   "source": [
    "# Pick a sample from test set\n",
    "sample_row = test_df.sample(1).iloc[0]\n",
    "query_text = sample_row['text_for_tfidf']\n",
    "actual_ids = sample_row['author_ids']\n",
    "\n",
    "# Run the inference (using the verbose function we wrote previously)\n",
    "rec_id, match_article_id, method = recommend_reviewer_logic_verbose(query_text)\n",
    "\n",
    "# Get Names\n",
    "actual_names = [get_author_name(aid) for aid in actual_ids]\n",
    "rec_name = get_author_name(rec_id)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL INFERENCE SUMMARY\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Actual Authors:      {actual_ids}\")\n",
    "print(f\"Actual Names:        {', '.join(actual_names)}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Recommended ID:      {rec_id}\")\n",
    "print(f\"Recommended Name:    {rec_name}\")\n",
    "print(f\"Selection Method:    {method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83477f52-e28f-4744-9905-8219026a9cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f549ae-c569-4236-a2c6-f5d48d274985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data-Treat",
   "language": "python",
   "name": "data-treat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
